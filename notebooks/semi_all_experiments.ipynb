{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised Experiments: Baseline, Self-Training, Co-Training, Ensemble\n",
    "\n",
    "Notebook này thực hiện toàn bộ quá trình huấn luyện và đánh giá, sau đó lưu kết quả để phục vụ báo cáo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Import library từ src\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src.classification_library import (\n",
    "    load_beijing_air_quality,\n",
    "    clean_air_quality_df,\n",
    "    add_pm25_24h_and_label,\n",
    "    add_time_features,\n",
    "    add_lag_features,\n",
    "    time_split,\n",
    "    train_classifier,\n",
    "    AQI_CLASSES\n",
    ")\n",
    "from src.semi_supervised_library import (\n",
    "    SemiDataConfig,\n",
    "    SelfTrainingConfig,\n",
    "    CoTrainingConfig,\n",
    "    SelfTrainingAQIClassifier,\n",
    "    CoTrainingAQIClassifier,\n",
    "    _normalize_missing\n",
    ")\n",
    "\n",
    "# Config\n",
    "CUTOFF = \"2017-01-01\"\n",
    "RAW_ZIP_PATH = \"../data/raw/PRSA2017_Data_20130301-20170228.zip\"\n",
    "OUTPUT_METRICS_PATH = \"../data/processed/semi_experiments_results.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Train size: 396264, Labeled: 118879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_6984\\2223031234.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Moderate' 'Moderate' 'Very_Unhealthy' ...\n",
      " 'Unhealthy_for_Sensitive_Groups' 'Unhealthy' 'Unhealthy']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  out.loc[labeled_indices, target_col] = original_labels.loc[labeled_indices]\n"
     ]
    }
   ],
   "source": [
    "# 1. Prepare Data\n",
    "print(\"Loading and preparing data...\")\n",
    "df = load_beijing_air_quality(use_ucimlrepo=False, raw_zip_path=RAW_ZIP_PATH)\n",
    "df = clean_air_quality_df(df)\n",
    "df = add_pm25_24h_and_label(df)\n",
    "df = add_time_features(df)\n",
    "df = add_lag_features(df, lag_hours=(1, 3, 24))\n",
    "df_clean = df.dropna(subset=[\"aqi_class\"]).copy()\n",
    "\n",
    "train_df, test_df = time_split(df_clean, cutoff=CUTOFF)\n",
    "\n",
    "# Mask labels (30% labeled)\n",
    "def mask_labels_exact_fraction(df, target_col, labeled_ratio=0.3, random_state=42):\n",
    "    out = df.copy()\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n_total = len(out)\n",
    "    n_labeled = int(n_total * labeled_ratio)\n",
    "    labeled_indices = rng.choice(out.index, size=n_labeled, replace=False)\n",
    "    original_labels = out[target_col].copy()\n",
    "    out[target_col] = np.nan\n",
    "    out.loc[labeled_indices, target_col] = original_labels.loc[labeled_indices]\n",
    "    return out\n",
    "\n",
    "semi_train_df = mask_labels_exact_fraction(train_df, \"aqi_class\", labeled_ratio=0.3)\n",
    "print(f\"Train size: {len(semi_train_df)}, Labeled: {semi_train_df['aqi_class'].notna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline...\n"
     ]
    }
   ],
   "source": [
    "results_summary = []\n",
    "\n",
    "# 2. Baseline\n",
    "print(\"Running Baseline...\")\n",
    "baseline_train_df = semi_train_df.dropna(subset=[\"aqi_class\"]).copy()\n",
    "base_res = train_classifier(baseline_train_df, test_df, target_col=\"aqi_class\")\n",
    "results_summary.append({\n",
    "    \"Method\": \"Baseline (30%)\",\n",
    "    \"Accuracy\": base_res[\"metrics\"][\"accuracy\"],\n",
    "    \"Macro-F1\": base_res[\"metrics\"][\"f1_macro\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Self-Training...\n"
     ]
    }
   ],
   "source": [
    "# 3. Self-Training\n",
    "print(\"Running Self-Training...\")\n",
    "data_cfg = SemiDataConfig(cutoff=CUTOFF, target_col=\"aqi_class\")\n",
    "st_cfg = SelfTrainingConfig(tau=0.90, max_iter=10, min_new_per_iter=50, val_frac=0.2)\n",
    "\n",
    "st_model = SelfTrainingAQIClassifier(data_cfg, st_cfg)\n",
    "st_model.fit(semi_train_df)\n",
    "\n",
    "# Eval\n",
    "feat_cols = st_model.info_[\"feature_cols\"]\n",
    "X_test = _normalize_missing(test_df[feat_cols].copy())\n",
    "y_test = test_df[\"aqi_class\"].astype(\"object\")\n",
    "y_pred_st = st_model.model_.predict(X_test)\n",
    "\n",
    "acc_st = accuracy_score(y_test, y_pred_st)\n",
    "f1_st = f1_score(y_test, y_pred_st, average=\"macro\")\n",
    "results_summary.append({\n",
    "    \"Method\": \"Self-Training\",\n",
    "    \"Accuracy\": acc_st,\n",
    "    \"Macro-F1\": f1_st\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Co-Training\n",
    "print(\"Running Co-Training...\")\n",
    "all_cols = train_df.columns.tolist()\n",
    "view1_cols = [\"month\", \"day\", \"hour\", \"dow\", \"is_weekend\", \"hour_sin\", \"hour_cos\"] + [c for c in all_cols if \"_lag\" in c]\n",
    "weather_vars = [\"TEMP\", \"PRES\", \"DEWP\", \"RAIN\", \"WSPM\", \"SO2\", \"NO2\", \"CO\", \"O3\", \"PM10\"]\n",
    "view2_cols = [c for c in weather_vars if c in all_cols]\n",
    "\n",
    "ct_cfg = CoTrainingConfig(tau=0.90, max_iter=10, max_new_per_iter=200, min_new_per_iter=10, val_frac=0.2)\n",
    "ct_model = CoTrainingAQIClassifier(data_cfg, ct_cfg, view1_cols=view1_cols, view2_cols=view2_cols)\n",
    "ct_model.fit(semi_train_df)\n",
    "\n",
    "# Eval Co-Training (Soft Voting inside predict)\n",
    "y_pred_ct = ct_model.predict(test_df)\n",
    "acc_ct = accuracy_score(y_test, y_pred_ct)\n",
    "f1_ct = f1_score(y_test, y_pred_ct, average=\"macro\")\n",
    "results_summary.append({\n",
    "    \"Method\": \"Co-Training\",\n",
    "    \"Accuracy\": acc_ct,\n",
    "    \"Macro-F1\": f1_ct\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Ensemble (Explicit Soft Voting from Co-Training Models)\n",
    "print(\"Running Ensemble Evaluation...\")\n",
    "model_v1 = ct_model.model1_\n",
    "model_v2 = ct_model.model2_\n",
    "\n",
    "X_test_v1 = _normalize_missing(test_df[ct_model.info_[\"view1_cols\"]].copy())\n",
    "X_test_v2 = _normalize_missing(test_df[ct_model.info_[\"view2_cols\"]].copy())\n",
    "\n",
    "proba_v1 = model_v1.predict_proba(X_test_v1)\n",
    "proba_v2 = model_v2.predict_proba(X_test_v2)\n",
    "\n",
    "def align_proba(model, proba, labels):\n",
    "    out = np.zeros((proba.shape[0], len(labels)), dtype=float)\n",
    "    class_to_pos = {str(c): i for i, c in enumerate(model.named_steps[\"model\"].classes_)}\n",
    "    for j, lab in enumerate(labels):\n",
    "        if lab in class_to_pos:\n",
    "            out[:, j] = proba[:, class_to_pos[lab]]\n",
    "    return out\n",
    "\n",
    "p1 = align_proba(model_v1, proba_v1, AQI_CLASSES)\n",
    "p2 = align_proba(model_v2, proba_v2, AQI_CLASSES)\n",
    "p_ens = (p1 + p2) / 2.0\n",
    "y_pred_ens = np.array(AQI_CLASSES)[p_ens.argmax(axis=1)]\n",
    "\n",
    "acc_ens = accuracy_score(y_test, y_pred_ens)\n",
    "f1_ens = f1_score(y_test, y_pred_ens, average=\"macro\")\n",
    "results_summary.append({\n",
    "    \"Method\": \"Ensemble\",\n",
    "    \"Accuracy\": acc_ens,\n",
    "    \"Macro-F1\": f1_ens\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Save Results\n",
    "final_data = {\n",
    "    \"summary\": results_summary,\n",
    "    \"history_st\": st_model.history_,\n",
    "    \"history_ct\": ct_model.history_\n",
    "}\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_METRICS_PATH), exist_ok=True)\n",
    "with open(OUTPUT_METRICS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Đã lưu kết quả thực nghiệm vào: {OUTPUT_METRICS_PATH}\")\n",
    "print(json.dumps(results_summary, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (beijing_env)",
   "language": "python",
   "name": "beijing_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
