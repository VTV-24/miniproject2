{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e07b08e3",
      "metadata": {},
      "source": [
        "# 03 — Classification Modelling\n",
        "Mục tiêu: train mô hình phân lớp AQI (6 lớp), split theo thời gian, đánh giá bằng accuracy + macro-F1, confusion matrix, và lưu metrics/prediction sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac78aab7",
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = 'data/processed/dataset_for_clf.parquet'\n",
        "CUTOFF = '2017-01-01'\n",
        "METRICS_PATH = 'data/processed/metrics.json'\n",
        "PRED_SAMPLE_PATH = 'data/processed/predictions_sample.csv'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "085f59f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src.classification_library import time_split, train_classifier, AQI_CLASSES\n",
        "\n",
        "# ===== Auto detect PROJECT_ROOT (compatible with papermill) =====\n",
        "HERE = Path.cwd()\n",
        "PROJECT_ROOT = HERE\n",
        "while not (PROJECT_ROOT / \"data\").exists() and PROJECT_ROOT != PROJECT_ROOT.parent:\n",
        "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
        "\n",
        "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
        "\n",
        "dataset_path = (PROJECT_ROOT / DATASET_PATH).resolve()\n",
        "metrics_path = (PROJECT_ROOT / METRICS_PATH).resolve()\n",
        "pred_path = (PROJECT_ROOT / PRED_SAMPLE_PATH).resolve()\n",
        "\n",
        "metrics_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "pred_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Dataset path:\", dataset_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3be4f4da",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_parquet(dataset_path)\n",
        "print('shape:', df.shape)\n",
        "df[['datetime','station','aqi_class']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da375c17",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df, test_df = time_split(df, cutoff=CUTOFF)\n",
        "print('train:', train_df.shape, '| test:', test_df.shape)\n",
        "print('test date range:', test_df['datetime'].min(), '->', test_df['datetime'].max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a44ecf91",
      "metadata": {},
      "outputs": [],
      "source": [
        "out = train_classifier(train_df, test_df, target_col='aqi_class')\n",
        "metrics = out['metrics']\n",
        "pred_df = out['pred_df']\n",
        "\n",
        "print('Accuracy:', metrics['accuracy'])\n",
        "print('F1-macro:', metrics['f1_macro'])\n",
        "pred_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e277072",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion matrix plot\n",
        "cm = np.array(metrics['confusion_matrix'])\n",
        "labels = metrics['labels']\n",
        "\n",
        "plt.figure(figsize=(9, 7))\n",
        "plt.imshow(cm)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xticks(range(len(labels)), labels, rotation=45, ha='right')\n",
        "plt.yticks(range(len(labels)), labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, str(int(cm[i, j])), ha='center', va='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13de44e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lưu metrics + sample prediction\n",
        "with open(metrics_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "pred_df.head(5000).to_csv(pred_path, index=False)\n",
        "print('Saved:', metrics_path)\n",
        "print('Saved:', pred_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f17d7f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# In classification report (rút gọn)\n",
        "report = metrics['report']\n",
        "summary = {k: report[k] for k in ['accuracy', 'macro avg', 'weighted avg'] if k in report}\n",
        "summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22d359de",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== Class distribution =====\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dist_all = df['aqi_class'].value_counts().sort_index()\n",
        "dist_test = test_df['aqi_class'].value_counts().sort_index()\n",
        "\n",
        "print(\"Class distribution (ALL):\")\n",
        "print(dist_all)\n",
        "\n",
        "print(\"\\nClass distribution (TEST):\")\n",
        "print(dist_test)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "dist_all.plot(kind='bar')\n",
        "plt.title(\"AQI Class Distribution - Full Dataset\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce1b6fc0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== Feature Importance =====\n",
        "\n",
        "model = out.get(\"model\", None)\n",
        "\n",
        "if model is not None and hasattr(model, \"feature_importances_\"):\n",
        "    importances = model.feature_importances_\n",
        "    feature_names = [c for c in train_df.columns if c not in ['aqi_class']]\n",
        "\n",
        "    fi = pd.Series(importances, index=feature_names).sort_values(ascending=False)\n",
        "\n",
        "    print(\"Top 15 important features:\")\n",
        "    print(fi.head(15))\n",
        "\n",
        "    plt.figure(figsize=(8,5))\n",
        "    fi.head(15).plot(kind='barh')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.title(\"Top 15 Feature Importances (Baseline Model)\")\n",
        "    plt.xlabel(\"Importance\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Model does not support feature importance.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b20d2bbb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== Compare with Semi-supervised (robust) =====\n",
        "import json\n",
        "\n",
        "self_path = PROJECT_ROOT / \"data/processed/metrics_self_training.json\"\n",
        "co_path = PROJECT_ROOT / \"data/processed/metrics_co_training.json\"\n",
        "\n",
        "rows = []\n",
        "\n",
        "# Baseline\n",
        "rows.append({\n",
        "    \"Model\": \"Supervised baseline\",\n",
        "    \"Accuracy\": metrics.get(\"accuracy\"),\n",
        "    \"F1-macro\": metrics.get(\"f1_macro\")\n",
        "})\n",
        "\n",
        "def extract_scores(m):\n",
        "    # try multiple possible structures\n",
        "    if \"accuracy\" in m:\n",
        "        return m.get(\"accuracy\"), m.get(\"f1_macro\")\n",
        "    if \"metrics\" in m:\n",
        "        return m[\"metrics\"].get(\"accuracy\"), m[\"metrics\"].get(\"f1_macro\")\n",
        "    if \"report\" in m and \"accuracy\" in m[\"report\"]:\n",
        "        return m[\"report\"][\"accuracy\"], None\n",
        "    return None, None\n",
        "\n",
        "# Self-training\n",
        "if self_path.exists():\n",
        "    with open(self_path) as f:\n",
        "        m = json.load(f)\n",
        "    acc, f1 = extract_scores(m)\n",
        "    rows.append({\n",
        "        \"Model\": \"Self-training\",\n",
        "        \"Accuracy\": acc,\n",
        "        \"F1-macro\": f1\n",
        "    })\n",
        "\n",
        "# Co-training\n",
        "if co_path.exists():\n",
        "    with open(co_path) as f:\n",
        "        m = json.load(f)\n",
        "    acc, f1 = extract_scores(m)\n",
        "    rows.append({\n",
        "        \"Model\": \"Co-training\",\n",
        "        \"Accuracy\": acc,\n",
        "        \"F1-macro\": f1\n",
        "    })\n",
        "\n",
        "compare_df = pd.DataFrame(rows)\n",
        "compare_df\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.9"
    },
    "title": "classification_modelling"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
