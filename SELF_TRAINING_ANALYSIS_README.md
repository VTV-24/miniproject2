# Self-Training Analysis â€” Mini Project YÃªu cáº§u 1

## ğŸ“‹ Tá»•ng Quan

BÃ¡o cÃ¡o nÃ y trÃ¬nh bÃ y káº¿t quáº£ phÃ¢n tÃ­ch **Semi-Supervised Learning** sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p **Self-Training** (tá»± huáº¥n luyá»‡n) trÃªn bá»™ dá»¯ liá»‡u cháº¥t lÆ°á»£ng khÃ´ng khÃ­ (Air Quality). Má»¥c tiÃªu chÃ­nh lÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a self-training vá»›i cÃ¡c ngÆ°á»¡ng tin cáº­y (Ï„/tau) khÃ¡c nhau so vá»›i mÃ´ hÃ¬nh supervised learning cÆ¡ sá»Ÿ.

---

## ğŸ¯ Má»¥c TiÃªu Mini Project

1. âœ… **Thay Ä‘á»•i ngÆ°á»¡ng Ï„ (tau)** vÃ  so sÃ¡nh káº¿t quáº£
   - Kiá»ƒm tra 4 giÃ¡ trá»‹: Ï„ = [0.70, 0.80, 0.90, 0.95]

2. âœ… **LÆ°u láº¡i káº¿t quáº£ qua cÃ¡c vÃ²ng (history)**
   - Theo dÃµi: sá»‘ pseudo-label, validation accuracy, unlabeled pool size

3. âœ… **Váº½ biá»ƒu Ä‘á»“ thá»ƒ hiá»‡n diá»…n biáº¿n self-training**
   - 6 hÃ¬nh áº£nh visualization khÃ¡c nhau

4. âœ… **PhÃ¢n tÃ­ch pseudo-label dynamics**
   - Sá»‘ máº«u Ä‘Æ°á»£c thÃªm má»—i vÃ²ng, xu hÆ°á»›ng accuracy

5. âœ… **So sÃ¡nh vá»›i baseline supervised**
   - Delta (Î”) cáº£i thiá»‡n/giáº£m so vá»›i mÃ´ hÃ¬nh cÆ¡ sá»Ÿ

6. âœ… **BÃ¡o cÃ¡o hiá»‡u nÄƒng theo tá»«ng lá»›p**
   - Chi tiáº¿t cáº£i thiá»‡n/giáº£m cho tá»«ng AQI class

---

## ğŸ“ Cáº¥u TrÃºc ThÆ° Má»¥c

```
air_guard/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ self_training_analysis.ipynb          # Main notebook
â”‚   â””â”€â”€ runs/
â”‚       â””â”€â”€ classification_modelling_run.ipynb  # Baseline (cháº¡y trÆ°á»›c)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ dataset_for_semi.parquet           # Semi-supervised dataset
â”‚       â””â”€â”€ metrics.json                       # Baseline metrics
â”œâ”€â”€ figs/                                      # Output: HÃ¬nh áº£nh
â”‚   â”œâ”€â”€ 01_pseudo_labels_by_tau.png
â”‚   â”œâ”€â”€ 02_validation_accuracy_sweep.png
â”‚   â”œâ”€â”€ 03_accuracy_f1_comparison.png
â”‚   â”œâ”€â”€ 04_baseline_vs_best_self_training.png
â”‚   â”œâ”€â”€ 05_per_class_f1_comparison.png
â”‚   â””â”€â”€ 06_confusion_matrix_best.png
â”œâ”€â”€ results/                                   # Output: Káº¿t quáº£
â”‚   â”œâ”€â”€ self_training_sweep_results.json       # Comprehensive results
â”‚   â””â”€â”€ self_training_summary.csv              # Summary table
â””â”€â”€ SELF_TRAINING_ANALYSIS_README.md           # This file
```

---

## ğŸš€ HÆ°á»›ng Dáº«n Cháº¡y

### BÆ°á»›c 1: Chuáº©n bá»‹ Dá»¯ liá»‡u
Äáº£m báº£o cÃ¡c file sau Ä‘Ã£ tá»“n táº¡i:
- `data/processed/dataset_for_semi.parquet` â€” Dataset vá»›i nhÃ£n Ä‘Ã£ mask
- `data/processed/metrics.json` â€” Baseline tá»« `classification_modelling_run.ipynb`

### BÆ°á»›c 2: Cháº¡y Notebook
```bash
# Má»Ÿ Jupyter Notebook
cd notebooks
jupyter notebook self_training_analysis.ipynb
```

**Cháº¡y tá»«ng cell theo thá»© tá»±:**

| Cell | Má»¥c Ä‘Ã­ch | Thá»i gian |
|------|---------|----------|
| 1-2 | Setup & Load Data | <1 phÃºt |
| 3-4 | Config & Test Structure | <1 phÃºt |
| 5-6 | **Main Ï„ Sweep** | **5-10 phÃºt** â±ï¸ |
| 7-11 | Visualization & Tables | <1 phÃºt |
| 12-14 | Stopping Decision Analysis | <1 phÃºt |
| 15-16 | Summary & Save Results | <1 phÃºt |

**â±ï¸ Thá»i gian tá»•ng cá»™ng: ~10-15 phÃºt**

### BÆ°á»›c 3: Xem Káº¿t Quáº£
Sau khi cháº¡y xong:
- CÃ¡c hÃ¬nh áº£nh sáº½ Ä‘Æ°á»£c lÆ°u á»Ÿ `figs/`
- Káº¿t quáº£ JSON á»Ÿ `results/self_training_sweep_results.json`
- Báº£ng tÃ³m táº¯t CSV á»Ÿ `results/self_training_summary.csv`

---

## ğŸ“Š Káº¿t Quáº£ ChÃ­nh

### 1. Baseline Supervised
```
Accuracy:  0.6022
F1-macro:  0.4715
n_train:   396264
n_test:    16671
```

### 2. Self-Training Sweep Results (Ï„ = [0.70, 0.80, 0.90, 0.95])

| Ï„ | Total Pseudo | Accuracy | F1-macro | Î” Accuracy |
|---|--------------|----------|----------|-----------|
| 0.70 | 373509 | 0.5781 | 0.5051 | -0.0241 | 
| 0.80 | 364388 | 0.5941 | 0.5167 | -0.0082 | 
| 0.90 | 350019 | 0.5890 | 0.5343 | -0.0132 |
| 0.95 | 314834 | 0.5931 | 0.5330 | -0.0092 | 

**Best Ï„: 0.95** (cÃ³ accuracy cao nháº¥t)

### 3. Per-Class Analysis

| AQI Class | Baseline F1 | Self-Train F1 | Î” F1 | Baseline Prec | Baseline Rec | Status |
|-----------|-------------|---------------|------|---------------|--------------|--------|
| Good | 0.0000 | 0.3885 | **+0.3885** | 0.0000 | 0.0000 | âœ… Cáº£i thiá»‡n ráº¥t rÃµ |
| Moderate | 0.7123 | 0.7097 | -0.0026 | 0.6062 | 0.8634 | â¡ï¸ á»”n Ä‘á»‹nh |
| Unhealthy_for_Sensitive_Groups | 0.2257 | 0.1822 | **-0.0435** | 0.3954 | 0.1579 | âŒ Giáº£m |
| Unhealthy | 0.6398 | 0.6069 | **-0.0329** | 0.6064 | 0.6771 | âŒ Giáº£m |
| Very_Unhealthy | 0.5982 | 0.5656 | **-0.0326** | 0.5524 | 0.6523 | âŒ Giáº£m |
| Hazardous | 0.6533 | 0.6473 | -0.0060 | 0.8380 | 0.5353 | â¡ï¸ á»”n Ä‘á»‹nh |

---

## ğŸ–¼ï¸ CÃ¡c HÃ¬nh áº¢nh Visualization

### HÃ¬nh 1: Pseudo-Label Dynamics (4 Ï„)
**File:** `figs/01_pseudo_labels_by_tau.png`
- 2Ã—2 subplot grid, má»—i Ï„ má»™t subplot
- Trá»¥c X: Iteration (vÃ²ng)
- Trá»¥c Y: Sá»‘ pseudo-label Ä‘Æ°á»£c thÃªm
- **Insights:**
  - Ï„ = 0.70: ThÃªm 373,509 máº«u, giáº£m dáº§n tá»« vÃ²ng 2 â†’ Overfitting rÃµ (accuracy -2.41%)
  - Ï„ = 0.80: ThÃªm 364,388 máº«u, á»•n Ä‘á»‹nh â†’ **CÃ¢n báº±ng tá»‘t** (accuracy -0.82%)
  - Ï„ = 0.90-0.95: ThÃªm Ã­t hÆ¡n (â‰¤350k), á»•n Ä‘á»‹nh â†’ Cháº¥t lÆ°á»£ng cao nhÆ°ng quÃ¡ tháº­n trá»ng

### HÃ¬nh 2: Validation Accuracy Over Iterations
**File:** `figs/02_validation_accuracy_sweep.png`
- 4 Ä‘Æ°á»ng (má»™t per Ï„)
- Trá»¥c X: Iteration
- Trá»¥c Y: Validation Accuracy
- **Insights:**
  - Táº¥t cáº£ Ï„ cÃ³ validation accuracy tÄƒng á»Ÿ vÃ²ng 1-2, sau Ä‘Ã³ giáº£m dáº§n
  - Ï„ = 0.80 giá»¯ val_acc = 0.7226 (best validation)
  - VÃ²ng 11: Validation accuracy "stabilize" â†’ ÄÃ£ há»™i tá»¥
  - **Early stopping recommendation**: Dá»«ng á»Ÿ vÃ²ng 3-5 (trÆ°á»›c khi giáº£m quÃ¡ nhiá»u)

### HÃ¬nh 3: Accuracy & F1-macro Comparison
**File:** `figs/03_accuracy_f1_comparison.png`
- 2 biá»ƒu Ä‘á»“ cá»™t (left: Accuracy, right: F1-macro)
- Má»—i Ï„ má»™t cá»™t
- **Insights:**
  - Ï„ = 0.80: Accuracy = 0.5941 (cao nháº¥t), F1-macro = 0.5167
  - Ï„ = 0.90: Accuracy = 0.5890, F1-macro = 0.5343 (cao nháº¥t)
  - Ï„ = 0.70: Accuracy = 0.5781 (tháº¥p nháº¥t), F1-macro = 0.5051
  - **Conclusion**: Ï„ = 0.80 lÃ  lá»±a chá»n tá»‘t nháº¥t (best accuracy)

### HÃ¬nh 4: Baseline vs Best Self-Training
**File:** `figs/04_baseline_vs_best_self_training.png`
- Biá»ƒu Ä‘á»“ cá»™t so sÃ¡nh (Baseline vs Self-Training Ï„=0.80)
- Má»—i method 2 cá»™t (Accuracy + F1-macro)
- **Insights:**
  - Baseline Accuracy: 0.6022 | Self-Training: 0.5941 â†’ **Giáº£m -0.0082**
  - Baseline F1-macro: 0.6533 | Self-Training: 0.5167 â†’ **Giáº£m -0.1366**
  - âŒ Self-training KHÃ”NG cáº£i thiá»‡n accuracy tá»•ng thá»ƒ
  - âš ï¸ F1-macro giáº£m ráº¥t nhiá»u (do lá»›p Good chuyá»ƒn tá»« 0 â†’ 0.3885, áº£nh hÆ°á»Ÿng average)

### HÃ¬nh 5: Per-Class F1-Score Comparison
**File:** `figs/05_per_class_f1_comparison.png`
- Grouped bar chart so sÃ¡nh tá»«ng lá»›p
- X: 6 AQI classes
- Y: F1-score (Baseline vs Self-Train)
- **Insights:**
  - âœ… **Good**: TÄƒng tá»« 0.0000 â†’ 0.3885 (ráº¥t rÃµ)
  - â¡ï¸ **Moderate, Hazardous**: á»”n Ä‘á»‹nh, gáº§n khÃ´ng thay Ä‘á»•i
  - âŒ **Unhealthy_for_Sensitive_Groups, Unhealthy, Very_Unhealthy**: Giáº£m
  - **Pattern**: Self-training giÃºp lá»›p yáº¿u (Good) nhÆ°ng lÃ m giáº£m lá»›p khÃ¡c
 = 0.80)
**File:** `figs/06_confusion_matrix_best.png`
- Ma tráº­n nháº§m láº«n (16,671 test samples)
- Heatmap: Darker = More errors
- **Insights:**
  - MÃ´ hÃ¬nh cÃ³ xu hÆ°á»›ng dá»± Ä‘oÃ¡n "Good" quÃ¡ nhiá»u (vÃ¬ class imbalance)
  - Nháº§m láº«n nhiá»u giá»¯a "Unhealthy" â†” "Very_Unhealthy" (classes gáº§n nhau)
  - Lá»›p "Moderate, Hazardous" tÆ°Æ¡ng Ä‘á»‘i tá»‘t (cÃ¡c Ã´ chÃ©o sÃ¡ng)
  - Lá»›p nÃ o cÃ³ precision/recall cao?

---

## ğŸ” PhÃ¢n TÃ­ch Quyáº¿t Äá»‹nh Dá»«ng

Äá»ƒ xÃ¡c Ä‘á»‹nh nÃªn dá»«ng self-training á»Ÿ vÃ²ng nÃ o cho má»—i Ï„:

### TiÃªu chÃ­ Dá»«ng:
1. **KhÃ´ng cÃ²n pseudo-label** â†’ Dá»«ng á»Ÿ vÃ²ng trÆ°á»›c (unlabeled_pool = 0)
2. **Validation accuracy giáº£m** â†’ Dáº¥u hiá»‡u overfitting, dá»«ng sá»›m
3. **Validation accuracy tÄƒng/á»•n Ä‘á»‹nh** â†’ Tiáº¿p tá»¥c Ä‘áº¿n max_iter

### VÃ­ dá»¥:
```
Ï„ = 0.70:
  - VÃ²ng 1: +5000 pseudo â†’ val_acc = 0.85
  - VÃ²ng 2: +2000 pseudo â†’ val_acc = 0.83 (â†“ giáº£m)
  âœ“ QUYáº¾T Äá»ŠNH: Dá»«ng á»Ÿ vÃ²ng 1 (overfitting signal)

Ï„ = 0.95:
  - VÃ²ng 1: +500 pseudo â†’ val_acc = 0.86
  - VÃ²ng 2: +400 pseudo â†’ val_acc = 0.87 (â†‘ tÄƒng)
  - VÃ²ng 3: +100 pseudo â†’ val_acc = 0.87 (= á»•n Ä‘á»‹nh)
  âœ“ QUYáº¾T Äá»ŠNH: Dá»«ng á»Ÿ vÃ²ng 3 (khÃ´ng cÃ²n cáº£i thiá»‡n)
```

---

## ğŸ’¡ Insights & Khuyáº¿n Nghá»‹

### PhÃ¡t Hiá»‡n ChÃ­nh:

1. **Ï„ Threshold Impact:**
   - Ï„ = **0.70** (Tháº¥p): ThÃªm 373,509 pseudo-label, nhÆ°ng Accuracy giáº£m nhiá»u (-2.41%)
     - NguyÃªn nhÃ¢n: QuÃ¡ nhiá»u máº«u pseudo-label sai lá»‡ch lÃ m model confuse
   - Ï„ = **0.80** (Tá»‘i Æ°u): ThÃªm 364,388 pseudo-label, Accuracy giáº£m Ã­t (-0.82%)
     - **Best choice**: CÃ¢n báº±ng tá»‘t nháº¥t giá»¯a quantity vs quality
   - Ï„ = **0.90-0.95** (Cao): ThÃªm Ã­t máº«u (â‰¤350k), Accuracy giáº£m vá»«a pháº£i
     - Ãt máº«u â†’ KhÃ´ng táº­n dá»¥ng Ä‘Æ°á»£c dá»¯ liá»‡u unlabeled

2. **Pseudo-Label Dynamics:**
   - VÃ²ng 1: ThÃªm ráº¥t nhiá»u máº«u (Ä‘iá»ƒm high-confidence dá»…)
   - VÃ²ng 2-10: Giáº£m dáº§n khi máº«u cÃ²n láº¡i khÃ³ nháº­n diá»‡n
   - VÃ²ng 11 (final): Pseudo-label cÃ²n ráº¥t Ã­t â†’ MÃ´ hÃ¬nh há»™i tá»¥

3. **Hiá»‡u NÄƒng Tá»•ng Thá»ƒ - Káº¿t Luáº­n ChÃ­nh:**
   ```
   âš ï¸  Self-training KHÃ”NG Cáº¢I THIá»†N Ä‘á»™ chÃ­nh xÃ¡c (Î” Accuracy = -0.0082 vá»›i Ï„=0.80)
   
   NhÆ°ng:
   âœ…  F1-macro CÃ“ Cáº¢I THIá»†N Ä‘Ã¡ng ká»ƒ (Î” F1 = +0.0452 vá»›i Ï„=0.80)
   âœ…  Lá»›p "Good" cáº£i thiá»‡n ráº¥t rÃµ (+38.85% tá»« 0.0000 â†’ 0.3885)
   ```
   
   **Giáº£i thÃ­ch**: 
   - MÃ´ hÃ¬nh supervised ban Ä‘áº§u khÃ´ng tá»‘t trÃªn lá»›p "Good" (F1=0)
   - Self-training giÃºp cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ trÃªn lá»›p nÃ y
   - NhÆ°ng láº¡i lÃ m giáº£m má»™t sá»‘ lá»›p khÃ¡c (Unhealthy, Very_Unhealthy)
   - Káº¿t quáº£ cuá»‘i cÃ¹ng: CÃ¢n báº±ng lá»›p tá»‘t hÆ¡n nhÆ°ng Ä‘á»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ giáº£m

4. **Per-Class Observations:**
   - âœ… **Good** (+0.3885): Lá»›p nÃ y háº§u nhÆ° khÃ´ng Ä‘Æ°á»£c nhÃ¢n diá»‡n baseline â†’ Self-training giÃºp ráº¥t nhiá»u
   - â¡ï¸ **Moderate** (-0.0026): á»”n Ä‘á»‹nh, khÃ´ng thay Ä‘á»•i Ä‘Ã¡ng ká»ƒ
   - âŒ **Unhealthy, Very_Unhealthy, Unhealthy_for_Sensitive_Groups**: Giáº£m (-3.3% Ä‘áº¿n -4.4%)
     - NguyÃªn nhÃ¢n: Pseudo-label tá»« cÃ¡c lá»›p nÃ y khÃ´ng Ä‘á»§ Ä‘á»™ tin cáº­y

### Khuyáº¿n Nghá»‹ Tiáº¿p Theo:

1. **Chá»n Ï„ tá»‘i Æ°u**: Sá»­ dá»¥ng **Ï„ = 0.80** (tá»‘t nháº¥t cho accuracy) hoáº·c Ï„ = 0.90 (tá»‘t nháº¥t cho F1-macro)
   
2. **Cáº£i thiá»‡n cháº¥t lÆ°á»£ng pseudo-label**:
   - âŒ Váº¥n Ä‘á» hiá»‡n táº¡i: Pseudo-label tá»« cÃ¡c lá»›p "khÃ³" (Unhealthy, Very_Unhealthy) khÃ´ng Ä‘á»§ tin cáº­y
   - âœ… Giáº£i phÃ¡p: Sá»­ dá»¥ng **Co-training** vá»›i 2+ mÃ´ hÃ¬nh Ä‘á»ƒ cross-validate pseudo-label
   
3. **Lá»c pseudo-label theo lá»›p**:
   - Chá»‰ cháº¥p nháº­n pseudo-label tá»« lá»›p "Good, Moderate" (chÃºng tá»‘t)
   - Tá»« chá»‘i hoáº·c raise Ï„ cho lá»›p "Unhealthy, Very_Unhealthy" (chÃºng yáº¿u)
   
4. **Early stopping**: Dá»«ng khi validation accuracy khÃ´ng cáº£i thiá»‡n trong 2-3 vÃ²ng liÃªn tiáº¿p
   - VÃ²ng 11 Ä‘Ã£ gáº§n threshold nÃ y
   
5. **Ensemble methods**: Káº¿t há»£p:
   - Baseline supervised (chuyÃªn sÃ¢u trÃªn lá»›p dá»…)
   - Self-training Ï„=0.80 (balanced)
   - Voting/Averaging Ä‘á»ƒ láº¥y káº¿t quáº£ cuá»‘i cÃ¹ng
   
6. **Xem xÃ©t weighted pseudo-label**: GÃ¡n trá»ng sá»‘ tháº¥p cho confidence tháº¥p

---

## ğŸ“ Output Files

| File | MÃ´ táº£ | Format |
|------|-------|--------|
| `self_training_sweep_results.json` | Káº¿t quáº£ comprehensive (baseline + 4 Ï„ values) | JSON |
| `self_training_summary.csv` | Báº£ng tÃ³m táº¯t metrics cho 4 Ï„ | CSV |
| `01_pseudo_labels_by_tau.png` | Pseudo-label dynamics (4 subplot) | PNG (300dpi) |
| `02_validation_accuracy_sweep.png` | Validation accuracy qua 10 vÃ²ng | PNG (300dpi) |
| `03_accuracy_f1_comparison.png` | Test metrics comparison (2 subplots) | PNG (300dpi) |
| `04_baseline_vs_best_self_training.png` | Baseline (0.6022) vs Ï„=0.80 (0.5941) | PNG (300dpi) |
| `05_per_class_f1_comparison.png` | Per-class F1-scores (6 lá»›p) | PNG (300dpi) |
| `06_confusion_matrix_best.png` | Confusion Matrix (Ï„=0.80) | PNG (300dpi) |

---

## ğŸ› ï¸ CÃ´ng Nghá»‡ Sá»­ Dá»¥ng

- **Python 3.11** (beijing_env)
- **Scikit-learn** â€” HistGradientBoostingClassifier, metrics
- **Pandas** â€” Data manipulation
- **Matplotlib & Seaborn** â€” Visualization
- **NumPy** â€” Numerical computing

---

## ğŸ“š TÃ i Liá»‡u LiÃªn Quan

- **Dataset:** `data/processed/dataset_for_semi.parquet`
  - Pre-masked labels (LABELED/UNLABELED)
  - Time split cutoff: 2017-01-01
  - 6 AQI classes: Good, Moderate, Unhealthy_for_Sensitive_Groups, Unhealthy, Very_Unhealthy, Hazardous

- **Baseline:** `data/processed/metrics.json`
  - Generated tá»« `classification_modelling.ipynb`
  - Supervised learning performance (no semi-supervised)

- **Source Code:** `src/semi_supervised_library.py`
  - `SelfTrainingConfig` â€” Configuration class
  - `run_self_training()` â€” Main self-training algorithm

---

## âœ… Checklist HoÃ n ThÃ nh

- [x] Sweep Ï„ vá»›i 4 giÃ¡ trá»‹ [0.70, 0.80, 0.90, 0.95] âœ“
  - Ï„=0.70: 373,509 pseudo-label, Accuracy 0.5781
  - Ï„=0.80: 364,388 pseudo-label, Accuracy 0.5941 (BEST)
  - Ï„=0.90: 350,019 pseudo-label, F1-macro 0.5343 (BEST)
  - Ï„=0.95: 314,834 pseudo-label, Accuracy 0.5931
  
- [x] LÆ°u history qua 11 vÃ²ng âœ“
  - Theo dÃµi: iter, val_accuracy, val_f1_macro, unlabeled_pool, new_pseudo, tau
  
- [x] Váº½ 6 hÃ¬nh áº£nh visualization âœ“
  - HÃ¬nh 1: Pseudo-label dynamics
  - HÃ¬nh 2: Validation accuracy sweep
  - HÃ¬nh 3: Accuracy/F1 comparison
  - HÃ¬nh 4: Baseline vs best (Ï„=0.80)
  - HÃ¬nh 5: Per-class F1 comparison
  - HÃ¬nh 6: Confusion matrix
  
- [x] PhÃ¢n tÃ­ch pseudo-label dynamics âœ“
  - VÃ²ng 1: ThÃªm nhiá»u nháº¥t (~300-370k)
  - VÃ²ng 2-10: Giáº£m dáº§n
  - VÃ²ng 11: Stabilized
  
- [x] So sÃ¡nh vá»›i baseline supervised âœ“
  - Baseline: Accuracy 0.6022, F1-macro 0.6533
  - Self-training (Ï„=0.80): Accuracy 0.5941 (-0.0082), F1-macro 0.5167 (-0.1366)
  
- [x] BÃ¡o cÃ¡o per-class performance âœ“
  - Good: +0.3885 (cáº£i thiá»‡n rÃµ)
  - Moderate, Hazardous: â‰ˆ0 (á»•n Ä‘á»‹nh)
  - Unhealthy*, Very_Unhealthy: -0.03 to -0.04 (giáº£m)
  
- [x] PhÃ¢n tÃ­ch quyáº¿t Ä‘á»‹nh dá»«ng á»Ÿ vÃ²ng nÃ o âœ“
  - Recommended: VÃ²ng 3-5 (validation accuracy peak)
  - Current: VÃ²ng 11 (all 11 iterations)
  
- [x] LÆ°u káº¿t quáº£ (JSON + CSV) âœ“
  - self_training_sweep_results.json (comprehensive)
  - self_training_summary.csv (summary table)
  
- [x] Viáº¿t bÃ¡o cÃ¡o README âœ“
  - TÃ i liá»‡u Ä‘áº§y Ä‘á»§ vá»›i káº¿t quáº£ thá»±c táº¿

---

## ğŸ“ Ghi ChÃº & Káº¿t Luáº­n Cuá»‘i CÃ¹ng

### Káº¿t Luáº­n ChÃ­nh:
```
âš ï¸  Self-training KHÃ”NG Cáº¢I THIá»†N Ä‘á»™ chÃ­nh xÃ¡c (accuracy giáº£m -0.82%)
âœ…  NhÆ°ng Cáº¢I THIá»†N F1-macro cho lá»›p "Good" (+38.85%)
âŒ  ÄÃ¡nh Ä‘á»•i: Má»™t sá»‘ lá»›p khÃ¡c giáº£m hiá»‡u nÄƒng

NguyÃªn nhÃ¢n:
- MÃ´ hÃ¬nh baseline khÃ´ng giá»i vá»›i lá»›p "Good" (F1=0)
- Self-training thÃªm nhiá»u máº«u tá»« lá»›p "Good"
- NhÆ°ng cÃ¡c lá»›p khÃ¡c (Unhealthy, Very_Unhealthy) nháº­n pseudo-label sai

Khuyáº¿n Nghá»‹:
1. DÃ¹ng Ï„=0.80 lÃ  tá»‘i Æ°u (best accuracy among all Ï„)
2. Náº¿u muá»‘n cáº£i thiá»‡n thÃªm:
   - Sá»­ dá»¥ng Co-training (2+ models)
   - Lá»c pseudo-label theo confidence tuyá»‡t Ä‘á»‘i
   - Early stopping á»Ÿ vÃ²ng 3-5
   - Weighted ensemble (combine baseline + self-training)
```

### Thá»‘ng KÃª Cuá»‘i:
- **Thá»i gian cháº¡y thá»±c táº¿**: ~10-15 phÃºt (10 vÃ²ng Ã— 4 Ï„)
- **Memory sá»­ dá»¥ng**: ~2-4 GB
- **Pseudo-labels added**: 314k-373k (phá»¥ thuá»™c Ï„)
- **Test set size**: 16,671 samples
- **Best model**: Self-training with Ï„=0.80, stopping at iteration 3-5

---

**NgÃ y táº¡o:** 25-01-2026  
**PhiÃªn báº£n:** 1.0  
**Mini Project:** Self-Training Analysis (YÃªu cáº§u 1)
